% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/imputation.R
\name{soft_fit}
\alias{soft_fit}
\title{soft imputation.}
\usage{
soft_fit(data, outcome, n_impute = 10, step_size = 1,
  scale_data = TRUE, scale_lambda = 0.95, lambda_sequence = NULL,
  verbose = TRUE, ...)
}
\arguments{
\item{data}{data.frame or matrix}

\item{n_impute}{An integer indicating the number of multiply imputed
datasets to create.}

\item{step_size}{An integer indicating the number by which to increase
the maximum rank of the softImpute solution after each iteration.}

\item{verbose}{\code{TRUE} or \code{FALSE}. if \code{TRUE}, output will be
printed to the console indicating the ranks of solutions found
for the softImpute fits.}

\item{...}{Arguments passed on to \code{softImpute::softImpute}
\describe{
  \item{type}{two algorithms are implements, \code{type="svd"} or
  the default  \code{type="als"}. The "svd" algorithm repeatedly computes
  the svd of the completed matrix, and soft thresholds its singular
  values. Each new soft-thresholded svd is used to re-impute the missing
  entries. For large matrices of class \code{"Incomplete"}, the svd is
  achieved by an efficient form of alternating orthogonal ridge
  regression. The "als" algorithm uses this same alternating ridge
  regression, but updates the imputation at each step, leading to quite
  substantial speedups in some cases. The "als" approach does not
  currently have the same theoretical  convergence guarantees as the
  "svd" approach.
  }
  \item{thresh}{
convergence threshold, measured as the relative change in the Frobenius
norm between two successive estimates.
}
  \item{maxit}{
    maximum number of iterations.
  }
  \item{final.svd}{
only applicable to \code{type="als"}. The alternating ridge-regressions
do not lead to exact zeros. With the default \code{final.svd=TRUE}, at
the final iteration, a one step unregularized iteration is performed,
followed by soft-thresholding of the singular values, leading to hard zeros.
}
}}
}
\value{
a \code{list} of soft fit objects
}
\description{
an adaptation of the soft impute algorithm for
multiply imputed data.
}
\note{
see \link[softImpute:softImpute]{softimpute} for a more
descriptive summary of the \code{softImpute} algorithm.
}
\references{
Rahul Mazumder, Trevor Hastie and Rob Tibshirani (2010)
Spectral Regularization Algorithms for Learning Large Incomplete
Matrices, http://www.stanford.edu/~hastie/Papers/mazumder10a.pdf
\emph{Journal of Machine Learning Research} 11 (2010) 2287-2322
}
\author{
Trevor Hastie, Rahul Mazumder
}
