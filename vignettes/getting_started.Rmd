---
title: "Getting started with `ipa`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{getting_started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Overview

The `ipa` package helps create collections of imputed datasets using a specific method. The datasets are differentiated by specific tuning parameters that correspond to the method. For example, the number of neighbors used to impute missing values is a specific parameter for nearest neighbor imputation. True to its name, `ipa` is based around the process of brewing a great beer. The main steps involved are

1. `brew` Create a container to hold your imputations

2. `spice` (optional) set parameters that govern the number of imputations for the given brew

3. `mash` fit models that will provide imputations

4. `ferment` impute missing values in training and (optionally) testing data 

5. `bottle` output the imputed datasets in a tibble.

# Diabetes data

```{r}

library(ipa)
library(magrittr)
library(recipes)
library(rsample)
library(parsnip)
library(yardstick)
library(dplyr)
library(purrr)
library(ggplot2)

# random seed for reproducing these results
set.seed(329)

data("Diabetes", package = 'Publish')

diab_complete <- diab_missing <- as_tibble(Diabetes) %>%
  select(-id, -bp.2s, -bp.2d, -AgeGroups, -BMI) %>%
  rename(
    sbp = bp.1s,
    dbp = bp.1d,
    height_cm = height.europe,
    weight_kg = weight.europe,
    time_ppn = time.ppn,
    stable_glucose = stab.glu
  ) %>%
  mutate(diabetes = as.numeric(glyhb > 7)) %>%
  select(-glyhb, -location) %>%
  drop_na() 


rows <- sample(nrow(diab_complete), 200)

for(i in rows){
  
  cols <- sample(ncol(diab_complete)-1, size = ncol(diab_complete) - 5)
  diab_missing[i, cols] <- NA
  
}

diab_complete %<>% 
  data.table::as.data.table() %>% 
  mltools::one_hot() %>% 
  as_tibble() %>% 
  select(-gender_female, -frame_large)

diab_missing %<>% 
  data.table::as.data.table() %>% 
  mltools::one_hot() %>% 
  as_tibble() %>% 
  select(-gender_female, -frame_large)



```

## Problem description

A common task for prediction model development is handling missing values. `ipa` helps analysts access more options as they engage with this task. This vignette shows some of `ipa`'s features in the context of an example where the modeling problem is classification of diabetes status. The complete are shown below

```{r}

glimpse(diab_complete)

```

The amputed data have roughly 40% missing value.

```{r}

glimpse(diab_missing)

```

We will fit a logistic regression model to these data after imputing missing values. Two questions stand out: 

1. Which imputation technique most accurately imputes missing values?

2. Which imputation technique provides the most accurate logistic regression model?

# Imputation accuracy

```{r}

n_imp <- 15
ls <- seq(25, 1, length.out = n_imp)

resamples <- vfold_cv(diab_missing, strata = 'diabetes')

resamples <- resamples %>% 
  mutate(
    soft_imp = map(
      .x = splits, 
      .f =  ~ {
        brew_soft(data = training(.x), outcome = diabetes) %>% 
          spice(with = spicer_soft(n_impute = n_imp, step_size = 1)) %>% 
          mash(with = masher_soft(scale_iter = 50, lambda_sequence = ls)) %>% 
          ferment(testing = test_stkr(testing(.x))) %>% 
          bottle(type = 'tibble')
      }
    ),
    nbrs_imp = map(
      .x = splits, 
      .f = ~ {
        brew_nbrs(data = training(.x), outcome = diabetes) %>% 
          spice(with = spicer_nbrs(neighbors = seq(6, 20))) %>% 
          mash() %>% 
          ferment(testing = test_nbrs(testing(.x))) %>% 
          bottle(type = 'tibble')
      }
    )
  )


resamples

```


```{r}

model_data <- resamples %>% 
  select(id, ends_with('imp')) %>% 
  pivot_longer(cols = ends_with('imp')) %>% 
  unnest(cols = value)

model_data

```



```{r}

model_data <- model_data %>% 
  mutate(
    training = map(training, mutate, diabetes = factor(diabetes)),
    testing = map(testing, mutate, diabetes = factor(diabetes)),
    logit_predprob = map2(
      .x = training, 
      .y = testing, 
      .f = ~ {
        logistic_reg() %>% 
          set_engine('glm') %>% 
          fit(diabetes ~ ., data = .x) %>% 
          predict(new_data = .y, type = 'prob')
      }
    )
  )

```


```{r}

results_data <- model_data %>%
  mutate(
    probs = map2(
      .x = testing, 
      .y = logit_predprob,
      .f = ~ {
        bind_cols(truth = .x$diabetes, .y)
      }
    )
  ) %>% 
  group_by(name, impute) %>% 
  summarize(
    probs = list(bind_rows(probs))
  )

```

```{r}

results <- results_data %>% 
  mutate(
    auc = map(
      .x = probs, 
      .f = yardstick::roc_auc, .pred_1, truth = truth
    )
  ) %>% 
  unnest_wider(col = auc)

```

```{r}

ggplot(results) + 
  aes(x = impute, y = .estimate) + 
  facet_wrap(~name) + 
  geom_line(col = 'grey') + 
  geom_point(shape = 21, col = 'black', fill = 'red')

```


## Standard approach

Imputation to the mean is a common strategy used to impute missing values for prediction models. We will use the performance of a linear model fitted to mean imputed data as a reference point for this example. 

```{r}


tmp = resamples %>% 
  mutate(
    ref = map_dbl(
      .x = splits, 
      .f = ~ {

        .reci <- prep(reci, training = training(.x))
        
        trn <- juice(.reci)
        tst <- bake(.reci, new_data = testing(.x))
        
        trn %<>% mutate(diabetes = factor(diabetes))
        tst %<>% mutate(diabetes = factor(diabetes))
        
        logistic_reg() %>% 
          set_engine('glm') %>% 
          fit(diabetes ~ ., data = trn) %>% 
          predict(new_data = tst, type = 'prob') %>% 
          yardstick::roc_auc(.pred_1, truth = tst$diabetes) %>% 
          pull(.estimate)
          
      }
    )
  )

# Model, predictions, and mean squared error
# using mean imputation (the reference approach)

ref_mdl <- lm(response ~ ., data = juice(reci))
ref_prd <- predict(ref_mdl, newdata = bake(reci, data$testing))
ref_mse <- mean((ref_prd - data$testing$response)^2)

```


## `softImpute`

soft imputation is a method based on singular value decomposition of a matrix. We will use the `softImpute` algorithm to brew a set of 20 imputed datasets with varying degrees of regularization. 

### Brew

When you start a brew, an object is initiated with an empty list containing meta data about your missing data strategy. 

```{r}

brew_sft <- data$training %>% 
  brew(outcome = response, flavor = 'softImpute')

brew_sft

```


### Spice (if you want to)

If you are going to make all these imputed datasets, you might as well make them how you like them. Spicing your brew gives you more control over how many datasets are created and the values of parameters that will be used to generate them.

Of course, different brews take different spices, and it is a little overwhelming trying to remember which spice goes where. For this reason, `ipa` includes helper functions (see `spicer_soft`, `spicer_nbrs`, and `spicer_rngr`) to help add the correct arguments into the `spice` function via the `with` input. 

```{r}

brew_sft <- brew_sft %>% 
  spice(with = spicer_soft(n_impute = 24, step_size = 2))

# Note that I chose step_size so that n_impute * step_size < max_rank
# (spice would throw an error at me if I messed that up)

brew_sft$pars

```


### Mash

Mashing the brew corresponds to the initiation of imputation for `ipa_brew` objects. Inputs of the `mash` function include parameters that directly correspond to imputation models. Again, different models take different parameters, so we rely on the `masher_soft` function to help us set parameters that matter for the `softImpute` algorithm.

Notably, the `softImpute` algorithm's convergence is influenced by parameters set in the `mash` function, and it is often helpful to see model fitting output printed to the screen to diagnose convergence problems. To see that output, we use the `set_verbose` function and make our brew a little noisier.

```{r}

brew_sft <- brew_sft %>% 
  verbose_on(level = 1) %>% 
  mash(with = masher_soft(scale_lambda = 0.90))

```

The `ipa_brew` object's `wort` will be filled with imputation models (i.e., the column called `fit`) after the mash is complete!

```{r}

brew_sft$wort

```

### Ferment

Missing values can occur in the training data but also the testing data. There are two few principles that `ipa` follows regarding missing values in testing data. 

1. Outcome columns should not be used to impute missing values. *Why?* First, the outcome column will naturally be missing in the testing data, so any imputation model that depends on accessing the outcome column will be unable to impute missing values in testing data. Second, foregoing the use of any outcome column in imputation models allows analysts to impute data and then apply cross-validation to tune downstream predictive models rather than re-imputing the data in each step of cross-validation (the second option requires far more computation time).   

2. A missing data strategy should not fit imputation models solely to the testing data. *Why?* Sometimes testing data are a single observation - it's hard to fit a model to that. 

There are at least two ways to handle missing data according to these principles. 

**Stack and fit:** Training and testing data are stacked. Imputation models are re-fitted to the stacked dataset.

**Training neighbors** A set of nearest neighbors in the training data is identified for each observation in the testing data. Observed values for these training observations are used to impute missing values in the testing data.

In an ideal world, imputation models are fitted to the training data and then applied to the testing data without needing to be re-fit. Unfortunately, some imputation strategies are not designed to work this way! For example, `softImpute` imputes missing values based on the index of the missing value in the training data, and this doesn't generalize to testing data because testing data (by definition) are not in the training data. However, the stack and fit strategy works quite well for `softImpute`.

The `...` argument in `ferment` lets you create a new column in the `wort` of the brew using the test impute strategy of your choice. For example, we'll use `test_stkr` below to apply the stack and fit strategy:

```{r}

brew_sft <- ferment(brew_sft, testing = test_stkr(data$testing))

brew_sft$wort

```

### Bottle

Once everything is imputed, your brew is ready to be bottled. You can choose whether you'd prefer to get the data back in the form of a `tibble` or `matrix`.

```{r}

brew_sft <- bottle(brew_sft, type = 'tibble')

brew_sft

```

### A pipe with your brew

The main functions in `ipa_brew` are designed to fit neatly with the `%>%` operator. We know you like to pipe while you brew.

```{r, eval = FALSE}

brew_sft <- data$training %>% 
  brew(outcome = response, flavor = 'softImpute') %>% 
  verbose_on(level = 1) %>% 
  spice(with = spicer_soft(n_impute = 24, step_size = 2)) %>% 
  mash(with = masher_soft(scale_lambda = 0.90)) %>% 
  ferment(testing = test_nbrs(data$testing)) %>% 
  bottle(type = 'tibble')

```

Now that we have our data, we can fit a linear model to each training set, and evaluate that model's predictions using the testing data. Our main questions are 

(1) can softImpute produce a model that is more accurate than mean imputation? 

(2) What are the ideal parameters for softImpute in this case?

```{r}

trn_yhat <- mean(data$training$response)
trn_mse <- mean((trn_yhat - data$testing$response)^2)

ggdat <- brew_sft %>% 
  mutate(
    sft_mse = map2_dbl(training, testing,
      .f = ~ lm(response ~ ., data = .x) %>% 
        predict(newdata = .y) %>% 
        subtract(data$testing$response) %>% 
        raise_to_power(2) %>% 
        mean()
    )
  ) %>% 
  select(impute, sft_mse) %>% 
  mutate(r2_sft = 1 - sft_mse / trn_mse)

```

Results show that all instances of softImpute have an advantage over mean imputation and that imputes 16-21 seem to provide the most accurate linear models. Using these imputed datasets rather than the reference approach (imputation to the mean) improves the testing r-squared statistic by approximately `r round(max(ggdat$r2_sft) - (1 - ref_mse / trn_mse), 3)` 

```{r, fig.width=7, fig.height=5}

ggplot(ggdat, aes(x = impute, y = r2_sft)) + 
  geom_line(col = 'grey') +
  geom_point(size = 2, shape = 21, fill = 'red', col = 'grey') + 
  geom_hline(yintercept = 1 - ref_mse / trn_mse, linetype = 2) +
  labs(x = 'Imputation', y = 'Testing R-squared statistic') + 
  theme_bw() + 
  theme(panel.grid = element_blank())

```


